# ShopShadow – Implementation Plan

**Memory Strategy:** dynamic-md
**Last Modification:** Initial creation by Setup Agent
**Project Overview:** ShopShadow is an automated checkout system using computer vision (YOLO11s) on Raspberry Pi to detect items customers add to their cart, with real-time updates to a web interface for payment. The system features a Node.js/Express backend, Flask detection service with USB camera, React frontend, PostgreSQL database, and a low-confidence item approval workflow for ML detections below 70% confidence threshold. MVP targets local MacBook development with future Raspberry Pi deployment.

---

## Phase 1: Foundation - Database & Project Setup

### Task 1.1 – Initialize monorepo project structure with directories │ Agent_Docs

- **Objective:** Establish the foundational directory structure for the ShopShadow monorepo with proper organization for backend, frontend, Flask detection service, documentation, and shared resources to enable parallel development across all agents.
- **Output:** Complete folder structure with backend/, flask-detection/, frontend/, docs/, .md-explanations/, shared/, tests/ directories, .gitignore files configured for Node.js and Python, and placeholder README.md files in each major directory.
- **Guidance:** Follow standard monorepo conventions with clear separation of concerns. Git repository should be initialized if not already present to support version control from project start.

- Create root-level directories: backend/, flask-detection/, frontend/ (existing), docs/, .md-explanations/, shared/, tests/ with appropriate permissions
- Set up .gitignore for Node.js (node_modules/, dist/, .env), Python (__pycache__/, *.pyc, venv/), environment files (.env, .env.local), and IDE-specific files (.vscode/, .idea/)
- Create placeholder README.md files in each major directory explaining directory purpose and intended contents to guide future development
- Initialize Git repository with initial commit if not already done, ensuring proper .gitignore is committed first

### Task 1.2 – Create PostgreSQL database schema design │ Agent_Database

- **Objective:** Design the complete database schema for ShopShadow including users, products, devices, orders, basket state, and approval workflow tables with proper relationships, constraints, and indexes to support all backend operations with future Supabase migration compatibility.
- **Output:** SQL schema definition file (schema.sql) containing CREATE TABLE statements for all 8 tables (users, products, devices, orders, order_items, sessions, basket_items, pending_items) with foreign keys, constraints, and indexes following frontend API specification.
- **Guidance:** Schema must match frontend API documentation exactly. Include comprehensive indexes for common query patterns (user lookups, basket polling, product searches). Add detailed SQL comments documenting Supabase compatibility considerations for future cloud migration.

1. **Define Core Tables:** Create users table (id UUID, name, email unique, password_hash, role enum, status, created_at, updated_at), products table (id VARCHAR, name, category, price decimal >=0, stock integer >=0, barcode unique, image_url), devices table (id UUID, code VARCHAR(4) unique, status enum, battery_level, connected_user_id FK), orders table (id VARCHAR, user_id FK, device_id FK, total, status enum, payment_id, basket_photo_url, created_at), order_items table (id UUID, order_id FK, product_id FK, name, quantity, price, subtotal computed), sessions table (id UUID, user_id FK, token, refresh_token, expires_at), basket_items table (id UUID, user_id FK, device_id FK, product_id FK, quantity, confidence, added_at), pending_items table (id UUID, user_id FK, device_id FK, product_id, name, quantity, confidence, status enum, timestamp) with columns and data types following frontend API spec from ShopShadow-Web/frontend/src/03-api-endpoints-and-data.md.
2. **Establish Relationships:** Add foreign key constraints with CASCADE/SET NULL rules (users ← orders, products ← order_items, devices ← basket_items, users ← basket_items) and ensure referential integrity for all table relationships.
3. **Add Business Constraints:** Implement CHECK constraints (price >= 0, stock >= 0, battery_level 0-100, status enums for user/device/order/pending_items), UNIQUE constraints (email, barcode, device code), NOT NULL constraints on required fields, and computed columns (in_stock GENERATED from stock > 0, subtotal GENERATED from quantity * price).
4. **Create Performance Indexes:** Add B-tree indexes for email lookup (users.email), product category filtering (products.category), order date queries (orders.created_at DESC), user order history (orders.user_id), basket polling (basket_items.user_id, basket_items.device_id), pending items retrieval (pending_items.user_id, pending_items.status), and product searches (products.name, products.barcode).
5. **Validate and Document:** Validate schema against frontend API documentation requirements ensuring all required fields are present, add SQL comments documenting Supabase compatibility considerations (UUID generation, timestamp formats, enum types, computed columns), and verify schema supports 5-second polling performance requirements for basket updates.

**Depends on:** None (foundational task)

### Task 1.3 – Implement database migration system │ Agent_Database

- **Objective:** Set up a robust database migration system using node-pg-migrate to manage schema changes with version control, rollback support, and future Supabase deployment compatibility, enabling safe database evolution throughout development.
- **Output:** Configured node-pg-migrate tool with package.json scripts (migrate:up, migrate:down, migrate:create), initial migration file containing Task 1.2 schema, .env database configuration template, and validated migration execution on local PostgreSQL.
- **Guidance:** Depends on Task 1.2 Output. Use node-pg-migrate for Node.js ecosystem consistency. Migration files must support both local PostgreSQL and future Supabase connection strings via environment variables.

1. **Install and Configure:** Run npm install --save-dev node-pg-migrate in backend/ directory, create .pgmigraterc configuration file with migrations directory path (backend/migrations/), database URL from environment variable (process.env.DATABASE_URL), and migration table name configuration.
2. **Create Initial Migration:** Generate initial migration file using npx node-pg-migrate create initial-schema, copy CREATE TABLE statements from Task 1.2 schema.sql into migration up() function, create corresponding DROP TABLE statements in down() function with proper CASCADE for foreign key cleanup, ensuring migration is idempotent and reversible.
3. **Configure Migration Scripts:** Add npm scripts to backend/package.json: "migrate:up": "node-pg-migrate up", "migrate:down": "node-pg-migrate down", "migrate:create": "node-pg-migrate create", configure DATABASE_URL in .env.example with local PostgreSQL format (postgresql://user:pass@localhost:5432/shopshadow) and Supabase-compatible format comments for future migration.
4. **Test and Validate:** Execute npm run migrate:up on local PostgreSQL to apply schema, verify all 8 tables created with correct structure using psql \dt and \d commands, execute npm run migrate:down to test rollback functionality, re-apply migration to confirm repeatability, and document migration workflow in backend/README.md.

**Depends on:** Task 1.2 Output

### Task 1.4 – Create seed data for product catalog │ Agent_Database

- **Objective:** Generate realistic seed data for development and testing including products mapped to COCO dataset classes, demo users with proper authentication, sample devices, and historical orders to populate the frontend with representative data.
- **Output:** SQL seed data file (seed.sql) or Node.js seeding script with INSERT statements for 15-20 products, 2 demo users (demo@email.com, admin@email.com), 2 sample devices, and 3-5 past orders, ready for execution after migrations.
- **Guidance:** Depends on Task 1.2 Output. Products must map to COCO dataset classes detectable by YOLO11s (apple, banana, bottle, etc.). Use bcrypt to hash passwords for demo users matching frontend login credentials (demo@email.com/1234, admin@email.com/1111).

- Create product seed data for 15-20 items mapped to COCO dataset classes (class 47='apple' → productId 'P001' name 'Organic Apples' price 1.99, class 46='banana' → 'P002' 'Fresh Bananas' 0.99, class 44='bottle' → 'P003' 'Water Bottle' 2.49, etc.) with realistic prices ($0.99-$15.99), appropriate categories (Fruits, Dairy, Bakery, Beverages, Pantry), stock levels (50-200 units), and optional image URLs matching frontend catalog structure
- Create demo users with INSERT statements: demo@email.com password '1234' hashed with bcrypt (salt rounds 10), role 'user', status 'active'; admin@email.com password '1111' hashed with bcrypt, role 'admin', status 'active', ensuring email_verified=true for immediate login capability
- Create sample devices with 4-digit codes: device code '0000' status 'disconnected', device code '1234' status 'disconnected', both with battery_level 100, firmware_version '1.0.0' for testing connection flow and code pairing functionality
- Create 3-5 sample past orders for demo user (user_id from demo@email.com) with order_items entries linking to seeded products, realistic totals ($15-$45), status 'completed', payment_method 'card', payment_id simulated, basket_photo_url placeholder, timestamps over past 7 days to populate order history page with representative data

**Depends on:** Task 1.2 Output

### Task 1.5 – Set up .env configuration templates │ Agent_Docs

- **Objective:** Create comprehensive .env.example template files for backend and Flask services documenting all required environment variables with clear explanations and example values to enable quick local development setup.
- **Output:** Two .env.example files (backend/.env.example, flask-detection/.env.example) with documented configuration variables, inline comments explaining each variable's purpose, and example values for local development.
- **Guidance:** Templates should include all variables needed for MVP development. Actual .env files should be .gitignored to protect secrets.

- Create backend/.env.example with documented variables and inline comments: DATABASE_URL="postgresql://user:password@localhost:5432/shopshadow" (PostgreSQL connection string for local development), JWT_SECRET="your-secret-key-here-generate-with-openssl-rand-base64-32" (secret for JWT signing), JWT_EXPIRES_IN="24h" (token expiration duration), API_PORT="3001" (Express server port), LOG_FILE_PATH="./logs" (directory for per-run log files), NODE_ENV="development" (environment mode), with comments explaining security considerations and production requirements
- Create flask-detection/.env.example with documented variables: BACKEND_API_URL="http://localhost:3001" (Node.js backend URL for API communication), YOLO_MODEL_PATH="./models/yolo11s.pt" (path to YOLO11s weights file), CAMERA_INDEX="0" (webcam index: 0 for MacBook built-in, 1+ for USB cameras), CONFIDENCE_THRESHOLD="0.7" (70% threshold for high/low confidence routing), DETECTION_INTERVAL="5" (seconds between detection cycles), LOG_FILE_PATH="./logs" (directory for detection event logs), with comments explaining how to configure for different cameras and network setups
- Add comments explaining each variable's purpose, example values for local development, security considerations (never commit actual .env files), and notes for production deployment (use strong secrets, configure HTTPS URLs, adjust thresholds based on testing)

**Depends on:** None

### Task 1.6 – Create logging infrastructure foundation │ Agent_Backend_Core

- **Objective:** Establish a shared logging infrastructure for both Node.js backend and Flask detection service with per-run file logging, console output, log rotation, and detailed error messages to support debugging and meet user requirement for comprehensive event logging.
- **Output:** Logging utility modules (shared/logger.js for Node.js, shared/logger.py for Python) with Winston/logging library configuration, per-run log file creation with timestamps, console formatting with colors, log rotation configuration, and usage documentation.
- **Guidance:** User requires detection events, API calls, and errors logged to both files AND console with detailed, easy-to-read messages. Implement per-run log files (timestamp-based filenames like shopshadow-2025-01-15-14-30-00.log) to separate execution sessions.

1. **Create Shared Logger Modules:** Implement shared/logger.js using Winston library with log level support (debug, info, warning, error), custom log format including timestamp (ISO 8601), log level, message, and optional metadata, logger instance configuration accepting log directory path from environment variable, and exports for each log level method (logger.debug(), logger.info(), logger.warn(), logger.error()). Implement shared/logger.py using Python logging module with equivalent log levels, custom formatter matching Node.js format for consistency, logger configuration accepting log directory from environment, and similar method exports.
2. **Configure File Logging:** Implement per-run log file creation with timestamp-based filenames (format: shopshadow-YYYY-MM-DD-HH-mm-ss.log) in LOG_FILE_PATH directory, create directory if not exists with proper permissions, configure Winston daily rotate transport (Winston-daily-rotate-file) with maxSize: '20m', maxFiles: '14d' to prevent disk filling, configure Python RotatingFileHandler with similar size/count limits, and ensure both loggers write to same file format for unified debugging.
3. **Set Up Console Output:** Configure Winston console transport with colorize enabled (info=green, warn=yellow, error=red), custom console format with timestamp prefix and aligned log levels for readability, configure Python StreamHandler with colorama for colored console output matching Node.js colors, implement detailed error message formatting including stack traces for errors, and ensure console output is human-readable during development.
4. **Document Usage:** Create shared/logger.md documenting logger import/initialization (const logger = require('../shared/logger'); logger.info('message')), available log levels and when to use each, per-run log file location and naming convention, log rotation policy and disk usage management, example log statements for common scenarios (API requests, detection events, errors), and integration instructions for backend and Flask services.

**Depends on:** None

---

## Phase 2: Backend API Core

### Task 2.1 – Set up Express.js server with middleware and base configuration │ Agent_Backend_Core

- **Objective:** Initialize the Express.js server foundation with essential middleware stack (CORS, body parsing, logging, error handling), PostgreSQL connection pooling, and server startup configuration to enable all backend API development.
- **Output:** Main Express server file (backend/src/server.js or index.js) with configured middleware stack, PostgreSQL connection pool using pg library, integrated Task 1.6 logging, global error handling middleware, and running server on port 3001.
- **Guidance:** Depends on Task 1.6 Output. Server must support CORS for frontend access, log all API requests using Task 1.6 shared/logger.js, handle database connection errors gracefully, and provide detailed error messages for debugging.

1. **Initialize Express App:** Run npm init -y in backend/ directory if package.json doesn't exist, install dependencies (npm install express pg dotenv bcrypt jsonwebtoken cors), create backend/src/server.js with Express initialization (const express = require('express'); const app = express();), load environment variables using dotenv.config() from root .env file, and configure server port from API_PORT environment variable (default 3001).
2. **Configure Core Middleware:** Add CORS middleware (app.use(cors({ origin: 'http://localhost:5173', credentials: true }))) allowing frontend Vite dev server access, add express.json() middleware for request body parsing with size limit (limit: '10mb') for base64 basket photos, add request logging middleware using Task 1.6 logger: app.use((req, res, next) => { logger.info(`${req.method} ${req.path}`); next(); }), and ensure middleware order is correct (CORS → body parsing → logging → routes).
3. **Set Up PostgreSQL Connection:** Import pg library (const { Pool } = require('pg');), create connection pool with configuration from DATABASE_URL environment variable (const pool = new Pool({ connectionString: process.env.DATABASE_URL, max: 10, idleTimeoutMillis: 30000 })), add connection error handling and logging (pool.on('error', (err) => logger.error('PostgreSQL pool error', err))), test connection on startup with pool.query('SELECT NOW()') and log success/failure, and export pool for use in route handlers.
4. **Integrate Logging System:** Import shared logger from Task 1.6 (const logger = require('../shared/logger');), add request logging middleware logging method, path, query params, and response status, add error logging for database queries and API endpoints, implement structured logging with metadata (userId, requestId) for debugging, and ensure all logs use Task 1.6 per-run log file.
5. **Configure Error Handling:** Implement global error handling middleware at end of middleware stack (app.use((err, req, res, next) => { ... })), log all errors with full stack traces using logger.error(), return detailed error messages in development (include stack trace) and generic messages in production, map error types to appropriate HTTP status codes (400 for validation, 401 for auth, 404 for not found, 500 for server errors), and ensure proper error response format ({ success: false, error: message, code: errorCode }).

**Depends on:** Task 1.6 Output

### Task 2.2 – Implement simplified JWT authentication system │ Agent_Backend_Core

- **Objective:** Create a simplified authentication system for MVP with password hashing using bcrypt, JWT token generation/verification, authentication middleware for protected routes, and login/signup/logout endpoints supporting user and admin roles.
- **Output:** Auth utility modules (backend/src/utils/auth.js with bcrypt and JWT functions), authentication middleware (backend/src/middleware/auth.js), auth route handlers (backend/src/routes/auth.js with POST /api/auth/login, POST /api/auth/signup, POST /api/auth/logout, POST /api/auth/refresh), and validated authentication flow.
- **Guidance:** Depends on Task 2.1 Output. Implement simplified JWT auth for MVP (full OAuth can be added later). Demo credentials: demo@email.com/1234, admin@email.com/1111. User roles (user, admin) must be fully implemented for access control.

1. **Create Password Utilities:** Implement backend/src/utils/auth.js with bcrypt import, hashPassword(password) function using bcrypt.hash() with salt rounds 10, comparePassword(password, hash) function using bcrypt.compare() for login validation, and exports for both functions with error handling for bcrypt failures.
2. **Implement JWT Functions:** Add JWT token generation in auth.js: generateToken(user) function creating JWT with payload { userId: user.id, email: user.email, role: user.role }, signing with JWT_SECRET from .env, setting expiration from JWT_EXPIRES_IN (24h), returning signed token; generateRefreshToken(user) function creating longer-lived refresh token (30d expiration); verifyToken(token) function using jwt.verify() with JWT_SECRET, returning decoded payload or throwing error; and token error handling for expired/invalid tokens.
3. **Create Auth Middleware:** Implement backend/src/middleware/auth.js exporting authenticateToken middleware that extracts Bearer token from Authorization header, verifies token using verifyToken(), attaches decoded user to req.user for route handlers, returns 401 if token missing/invalid, logs authentication attempts; implement requireAdmin middleware checking req.user.role === 'admin', returning 403 if not admin; and export both middleware functions for route protection.
4. **Implement Login Endpoint:** Create backend/src/routes/auth.js with POST /api/auth/login route handler that accepts { email, password } in request body, queries users table for matching email using PostgreSQL pool, returns 401 if user not found, uses comparePassword() to validate password hash, returns 401 if password incorrect, generates token and refreshToken using JWT functions, logs successful login with userId, returns { success: true, token, refreshToken, user: { id, name, email, role, createdAt } }, and validates input (email format, password presence).
5. **Implement Signup Endpoint:** Create POST /api/auth/signup route handler accepting { name, email, password }, validating email format and password strength (min 8 chars, 1 uppercase, 1 lowercase, 1 number), checking for existing email in users table (return 409 if duplicate), hashing password with hashPassword(), inserting new user with INSERT INTO users (name, email, password_hash, role, status) VALUES (...) with role='user' and status='active', generating token and refreshToken for immediate login, logging new user creation, returning { success: true, token, refreshToken, user } with 201 status.
6. **Implement Logout and Refresh:** Create POST /api/auth/logout endpoint that logs token invalidation (simplified for MVP - full token blacklist can be added later), disconnects user's device if deviceId provided in request body, returns { success: true, message: 'Logged out successfully' }; create POST /api/auth/refresh endpoint accepting { refreshToken }, verifying refresh token, generating new access token and refresh token, returning { success: true, token, refreshToken }, and logging token refresh events.
7. **Test Authentication Flow:** Create test script or use Postman to test signup with new user credentials, verify user created in database with hashed password, test login with correct credentials receives valid JWT, test login with incorrect credentials returns 401, test accessing protected route with valid token succeeds, test accessing protected route without token returns 401, test admin-only endpoint with user role returns 403, test admin-only endpoint with admin role succeeds, and document test results confirming authentication system works correctly.

**Depends on:** Task 2.1 Output

### Task 2.3 – Create product catalog API endpoints │ Agent_Backend_Catalog

- **Objective:** Implement REST API endpoints for product catalog operations including public product listing with filtering/search/pagination, single product details, and admin CRUD operations (create, update, delete) with proper validation and authentication.
- **Output:** Product route handlers (backend/src/routes/products.js) with GET /api/products (public, filtered list), GET /api/products/:productId (public, single product), POST /api/admin/products (admin, create), PUT /api/admin/products/:productId (admin, update), DELETE /api/admin/products/:productId (admin, delete), all validated against frontend API spec.
- **Guidance:** Depends on Task 2.2 Output by Agent_Backend_Core for auth middleware. Public endpoints (GET products) require no authentication. Admin endpoints require authenticateToken and requireAdmin middleware. Match frontend API spec exactly from ShopShadow-Web/frontend/src/03-api-endpoints-and-data.md.

1. **Implement Product Listing:** Create backend/src/routes/products.js with GET /api/products route handler (no auth required), extract query parameters (category, search, inStock, page=1, limit=50), build PostgreSQL query with WHERE clauses for filtering (category = $1 if provided, name ILIKE %$2% for search, in_stock = true if inStock=true), add pagination with OFFSET and LIMIT, execute query with pool.query(), count total matching products for pagination metadata, return { success: true, products: [{ id, name, category, price, stock, inStock, imageUrl, description, barcode }], pagination: { page, limit, total, totalPages }, categories: [unique categories array] }, cache response for 5 minutes (future optimization), and log query parameters and result count.
2. **Implement Single Product:** Create GET /api/products/:productId route handler (no auth), extract productId from req.params, query products table with SELECT * WHERE id = $1, return 404 if product not found, return { success: true, product: { id, name, category, price, stock, inStock, imageUrl, description, barcode, weight, nutritionFacts, allergens } } with full product details, cache individual product responses for 10 minutes, and log product access for analytics.
3. **Implement Admin Create/Update:** Create POST /api/admin/products route handler with authenticateToken and requireAdmin middleware, extract { name, category, price, stock, description, barcode, imageUrl } from request body, validate price > 0 and stock >= 0 returning 422 if validation fails, check barcode uniqueness returning 409 if duplicate, generate product id (P### format with auto-increment), INSERT INTO products with validated data, return 201 with { success: true, product: { id, name, category, price, stock, inStock, createdAt } }, log product creation; create PUT /api/admin/products/:productId with similar validation, UPDATE products SET ... WHERE id = $1, return 200 with updated product, handle 404 if product not found, and log product updates.
4. **Implement Admin Delete:** Create DELETE /api/admin/products/:productId route handler with admin auth, check if product has orders in last 90 days with SELECT COUNT(*) FROM order_items WHERE product_id = $1 AND created_at > NOW() - INTERVAL '90 days', return 409 { success: false, error: 'Cannot delete product', code: 'PRODUCT_IN_USE', affectedOrders: count } if orders exist, implement soft delete (UPDATE products SET deleted = true WHERE id = $1) or hard delete if no orders, return { success: true, message: 'Product deleted successfully' }, require admin confirmation in frontend before allowing delete, and log deletion events with admin user info.

**Depends on:** Task 2.2 Output by Agent_Backend_Core

### Task 2.4 – Implement device connection and pairing system │ Agent_Backend_Catalog

- **Objective:** Create the 4-digit code device connection system where Raspberry Pis register with the backend on boot to receive unique codes, users pair with devices by entering codes, and connection state is managed throughout shopping sessions.
- **Output:** Device route handlers (backend/src/routes/devices.js) with POST /api/devices/register (Pi registration), POST /api/devices/connect (user pairing), GET /api/devices/:deviceId/status (health check), POST /api/devices/disconnect (session end), code generation utilities, and connection state management.
- **Guidance:** Coordinates with Task 3.5 for device registration. Device codes are 4-digit strings (0000-9999) with uniqueness validation. Codes expire after 4 hours of inactivity. Connection associates deviceId with userId for basket state tracking.

1. **Implement Pi Registration:** Create backend/src/routes/devices.js with POST /api/devices/register route handler (no auth required - Pi calls this on boot), generate unique 4-digit code using crypto.randomInt(0, 10000).toString().padStart(4, '0'), check code uniqueness in devices table with SELECT WHERE code = $1, regenerate if duplicate (max 10 attempts), INSERT INTO devices (code, name, status, battery_level, firmware_version) VALUES ($1, 'Smart Basket #' + code, 'disconnected', 100, '1.0.0') or UPDATE existing device if one exists for this Pi instance, set code expiration timestamp (created_at + 4 hours), return { success: true, deviceId: uuid, code: '0000', websocketUrl: null } (websocket for future use), log device registration with code and deviceId, and handle registration failures with retry guidance.
2. **Create Code Generation Utility:** Implement backend/src/utils/deviceCodes.js with generateUniqueCode(pool) function that generates random 4-digit code, queries devices table for uniqueness, retries up to 10 times if collision, returns unique code or throws error if all attempts fail; implement isCodeExpired(device) function checking if (NOW() - device.created_at) > 4 hours, returning boolean; implement expireOldCodes() periodic cleanup function (can be cron job or middleware) that sets status='offline' for devices with expired codes; and export all functions for use in route handlers.
3. **Implement User Pairing:** Create POST /api/devices/connect route handler with authenticateToken middleware, extract { code, userId } from request body (userId from req.user), query devices table with SELECT * WHERE code = $1 AND status IN ('disconnected', 'offline'), return 404 { error: 'Invalid connection code', code: 'INVALID_CODE' } if device not found, check if code expired using isCodeExpired(), return 400 if expired with message to request new code, check if device already connected to another user returning 409 { error: 'Device already connected', code: 'DEVICE_IN_USE', connectedUntil: timestamp }, UPDATE devices SET connected_user_id = $1, status = 'connected', last_heartbeat = NOW() WHERE code = $2, return { success: true, device: { id, name, code, status: 'connected', batteryLevel, firmwareVersion, lastSync }, websocketUrl: null }, and log successful pairing with userId and deviceId.
4. **Implement Status Check:** Create GET /api/devices/:deviceId/status route handler with authenticateToken middleware, extract deviceId from params, query SELECT * FROM devices WHERE id = $1, return 404 if device not found, check if req.user.id matches device.connected_user_id (403 if not), return { success: true, device: { id, status, batteryLevel, itemCount: <query basket_items COUNT>, lastHeartbeat, signalStrength: 85 } }, implement heartbeat update (UPDATE devices SET last_heartbeat = NOW() WHERE id = $1) to maintain connection, auto-disconnect if no heartbeat for 5 minutes (status check shows 'offline' if last_heartbeat > 5 min ago), and log status checks for monitoring.
5. **Implement Disconnection:** Create POST /api/devices/disconnect route handler with authenticateToken middleware, extract { deviceId, userId } from request body, verify user owns this device connection (userId matches connected_user_id or user is admin), UPDATE devices SET connected_user_id = NULL, status = 'disconnected' WHERE id = $1, clear any remaining basket items for this device (DELETE FROM basket_items WHERE device_id = $1 - will be implemented in Task 2.5), return { success: true, message: 'Device disconnected successfully' }, handle case where device not connected (return success anyway for idempotency), and log disconnection events with reason (logout, checkout, timeout).

**Depends on:** None (coordinates with Task 3.5 for device registration)

### Task 2.5 – Create basket state management system │ Agent_Backend_Basket

- **Objective:** Implement the core basket state system using database basket_items table to store detected items per user session, handle add/remove operations from Flask detection service, support frontend polling for real-time updates, and manage basket cleanup on session end.
- **Output:** Basket route handlers (backend/src/routes/basket.js) with POST /api/basket/items (Flask adds high-confidence detections), GET /api/basket/:userId (frontend polling), basket cleanup logic integrated with disconnect/checkout, and basket state persistence in database.
- **Guidance:** Depends on Task 2.4 Output and coordinates with Task 3.5 for deviceId. Use database basket_items table (from Task 1.2 schema) for multi-device support and polling persistence. Frontend polls every 5 seconds. Basket cleared on disconnect and checkout completion.

1. **Design Basket Storage:** Verify basket_items table exists from Task 1.2 migrations with fields (id UUID PRIMARY KEY, user_id UUID FK users, device_id UUID FK devices, product_id VARCHAR FK products, quantity INTEGER, confidence DECIMAL, added_at TIMESTAMP DEFAULT NOW()), add INDEX on (user_id, device_id) for fast polling queries, add INDEX on product_id for duplicate detection, and document that database approach is chosen for multi-device support and persistence across page refreshes (vs in-memory which would lose state).
2. **Implement Flask Item Addition:** Create backend/src/routes/basket.js with POST /api/basket/items route handler (no auth required - Flask service calls this), extract { productId, quantity, confidence, deviceId } from request body sent by Flask detection (Task 3.5), query devices table to get connected_user_id for this deviceId, return 400 if device not connected to a user, check if same product already exists in basket with SELECT * FROM basket_items WHERE user_id = $1 AND device_id = $2 AND product_id = $3, if exists UPDATE basket_items SET quantity = quantity + $4, added_at = NOW() to aggregate quantities, if not exists INSERT INTO basket_items (user_id, device_id, product_id, quantity, confidence, added_at) VALUES (...), validate confidence >= 0.7 for auto-add (lower confidence should go to pending_items in Task 2.6), return { success: true, basketItem: { id, productId, quantity, confidence } }, log basket additions with detection confidence, and handle duplicate product updates properly (add quantities, don't create separate rows).
3. **Implement Quantity Aggregation:** Within POST /api/basket/items handler, when Flask sends multiple detections of same product in quick succession (e.g., 3 apples detected), aggregate quantity with UPDATE query (quantity = quantity + $1) instead of creating multiple rows, add business logic: if existing basket item has low confidence (<0.7) and new detection has high confidence (>=0.7), update confidence to higher value and add quantity, if multiple low-confidence detections of same item reach >= 0.7 average confidence, auto-approve and move to basket, and ensure quantity aggregation is atomic using database transaction (BEGIN; UPDATE; COMMIT;) to prevent race conditions from concurrent Flask detections.
4. **Implement Basket Retrieval:** Create GET /api/basket/:userId route handler with authenticateToken middleware, verify req.user.id matches :userId parameter (403 if not), query basket_items JOIN products to get full item details: SELECT basket_items.*, products.name, products.price, products.category, products.imageUrl FROM basket_items JOIN products ON basket_items.product_id = products.id WHERE basket_items.user_id = $1 ORDER BY basket_items.added_at DESC, calculate subtotal for each item (quantity * price), calculate total basket price SUM(quantity * price), return { success: true, items: [{ id, productId, name, quantity, price, subtotal, confidence, addedAt }], total: basketTotal }, handle empty basket (return empty array with total 0), and optimize query for 5-second polling performance (use prepared statement, indexes on user_id).
5. **Implement Basket Cleanup:** Create cleanupBasket(userId, deviceId, transaction) utility function in basket.js for reuse in disconnect and checkout flows, execute DELETE FROM basket_items WHERE user_id = $1 AND device_id = $2 within provided transaction (or create new transaction if none provided), log basket cleanup with userId and item count removed, integrate cleanup in Task 2.4 disconnect handler (call cleanupBasket when device disconnects), integrate cleanup in Task 2.7 order creation (call cleanupBasket after order snapshot within same transaction), and ensure cleanup is atomic to prevent partial deletions.

**Depends on:** Task 2.4 Output and coordinates with Task 3.5 for deviceId

### Task 2.6 – Implement low-confidence item approval endpoints │ Agent_Backend_Basket

- **Objective:** Create the approval workflow system for low-confidence detections (<70%) where items are stored as pending, users can retrieve pending items via polling, approve items with quantity adjustment to add to basket, or decline items, supporting the new low-confidence approval feature requirement.
- **Output:** Pending items route handlers (backend/src/routes/basket.js extended) with POST /api/basket/pending-items (Flask submits low confidence), GET /api/basket/:userId/pending-items (frontend polling), POST /api/basket/pending-items/:itemId/approve (user approval), POST /api/basket/pending-items/:itemId/decline (user rejection), and end-to-end tested approval workflow.
- **Guidance:** Depends on Task 2.5 Output. This is NEW FEATURE not in original frontend design. Pending items stored in database table from Task 1.2 schema. Approval moves item to basket_items, decline marks as declined with 24h cleanup.

1. **Design Pending Storage:** Verify pending_items table exists from Task 1.2 migrations with fields (id UUID PRIMARY KEY, user_id UUID FK users, device_id UUID FK devices, product_id VARCHAR FK products, name VARCHAR, quantity INTEGER, confidence DECIMAL, timestamp TIMESTAMP, status VARCHAR CHECK IN ('pending', 'approved', 'declined')), add INDEX on (user_id, status) for fast pending item retrieval, add INDEX on timestamp for cleanup queries, and document that database table is chosen for consistency with basket_items approach.
2. **Implement Flask Pending Submission:** Add POST /api/basket/pending-items route handler to basket.js (no auth - Flask calls this), extract { productId, name, quantity, confidence, deviceId } from Flask request body (Task 3.5), validate confidence < 0.7 (return 400 if >= 0.7 - should go to basket instead), query devices table to get connected_user_id for deviceId, return 400 if device not connected, INSERT INTO pending_items (user_id, device_id, product_id, name, quantity, confidence, timestamp, status) VALUES ($1, $2, $3, $4, $5, $6, NOW(), 'pending'), return { success: true, pendingItem: { id, productId, name, quantity, confidence, status: 'pending' } }, log pending item creation with confidence score, and include product name in pending_items (duplicating from products table) for display even if product later deleted.
3. **Implement Pending Retrieval:** Create GET /api/basket/:userId/pending-items route handler with authenticateToken middleware, verify req.user.id matches :userId (403 if not), query SELECT * FROM pending_items WHERE user_id = $1 AND status = 'pending' ORDER BY timestamp ASC to get oldest items first, return { success: true, pendingItems: [{ id, productId, name, quantity, confidence, timestamp }] }, filter to only status='pending' so approved/declined items don't show up, handle empty case (return empty array), optimize for 5-second polling alongside basket polling, and log pending item retrievals for monitoring user approval behavior.
4. **Implement Approval Endpoint:** Create POST /api/basket/pending-items/:itemId/approve route handler with authenticateToken middleware, extract itemId from params and { quantity } from request body (user can adjust detected quantity before approving), validate quantity > 0 returning 422 if invalid, query SELECT * FROM pending_items WHERE id = $1 AND status = 'pending', return 404 if pending item not found or already processed, verify pending_item.user_id matches req.user.id (403 if not), BEGIN TRANSACTION, INSERT INTO basket_items (user_id, device_id, product_id, quantity, confidence, added_at) VALUES (pending_item.user_id, pending_item.device_id, pending_item.product_id, $1, pending_item.confidence, NOW()) using user-adjusted quantity, UPDATE pending_items SET status = 'approved' WHERE id = $2, COMMIT TRANSACTION, query updated basket with JOIN products for full details, return { success: true, basketItem: { id, productId, name, quantity, price, subtotal }, basket: { items, total } } with updated basket state, log approval with original vs adjusted quantity, and handle transaction rollback on errors.
5. **Implement Decline Endpoint:** Create POST /api/basket/pending-items/:itemId/decline route handler with authenticateToken middleware, extract itemId from params, query SELECT * FROM pending_items WHERE id = $1 AND status = 'pending', return 404 if not found or already processed, verify user_id matches req.user.id (403 if not), UPDATE pending_items SET status = 'declined', timestamp = NOW() WHERE id = $1 (update timestamp for 24h cleanup calculation), return { success: true, message: 'Item declined' }, implement cleanup cron job (or middleware) that runs periodically: DELETE FROM pending_items WHERE status = 'declined' AND timestamp < NOW() - INTERVAL '24 hours', log declined items for ML model feedback, and consider declined items as user-corrected training data for future YOLO improvements.
6. **Test Approval Workflow:** Create test script simulating end-to-end flow: (1) Flask calls POST /api/basket/pending-items with low-confidence apple detection (confidence 0.65), verify pending_items table has row with status='pending', (2) Frontend calls GET /api/basket/:userId/pending-items, verify pending item returned, (3) User approves with POST /api/basket/pending-items/:itemId/approve with adjusted quantity 2, verify basket_items table has new row with quantity 2, verify pending_items status updated to 'approved', (4) GET /api/basket/:userId returns updated basket with approved item, (5) Test decline flow works similarly with status='declined', and document test results confirming workflow works correctly.

**Depends on:** Task 2.5 Output

### Task 2.7 – Create order and checkout API endpoints │ Agent_Backend_Orders

- **Objective:** Implement order creation on checkout completion with basket snapshot to order_items table, basket photo storage, order history retrieval with pagination, and single order details, supporting the complete checkout and order management workflow.
- **Output:** Order route handlers (backend/src/routes/orders.js) with POST /api/orders (create order from basket), GET /api/orders/user/:userId (order history), GET /api/orders/:orderId (order details), basket photo handling, and transaction-safe order creation with basket cleanup.
- **Guidance:** Depends on Task 2.5 Output by Agent_Backend_Basket for basket state. Order creation must be atomic transaction (create order + order_items + clear basket) to prevent data loss. Frontend passes payment ID from simulated payment for MVP.

1. **Implement Order Creation:** Create backend/src/routes/orders.js with POST /api/orders route handler with authenticateToken middleware, extract { userId, deviceId, items, total, paymentId, paymentMethod, basketPhotoBase64 } from request body, validate userId matches req.user.id, validate items array not empty (return 400 if empty basket), validate total matches sum of item prices * quantities (return 422 if mismatch), validate paymentId present (return 400 if missing - simulated payment for MVP), BEGIN TRANSACTION for atomicity, generate orderId (ORD-### format with auto-increment or UUID), INSERT INTO orders (id, user_id, device_id, total, status, payment_method, payment_id, created_at) VALUES ($1, $2, $3, $4, 'completed', $5, $6, NOW()), loop through items array creating order_items entries, call Task 2.5 cleanupBasket(userId, deviceId, transaction) to clear basket within transaction, COMMIT TRANSACTION, log successful order creation, return { success: true, order: { id, userId, deviceId, total, status: 'completed', items, basketPhotoUrl, paymentId, receiptUrl, createdAt } } with 201 status, and handle transaction rollback on any step failure.
2. **Implement Photo Storage:** Within POST /api/orders handler before transaction, extract basketPhotoBase64 (data:image/jpeg;base64,...) from request body, decode base64 to buffer, generate unique filename (orderId + '-basket-' + timestamp + '.jpg'), create orders/ directory in storage location if not exists (mkdir -p ./storage/orders/), write image buffer to file system (fs.writeFile('./storage/orders/' + filename)), store file path or URL in basketPhotoUrl field (for MVP use relative path, for production use S3/cloud storage URL), add basketPhotoUrl to order INSERT statement, handle storage errors gracefully (log error, continue order creation without photo - photo is nice-to-have), and document cloud storage migration path for production (upload to S3, store URL instead of local path).
3. **Implement Order History:** Create GET /api/orders/user/:userId route handler with authenticateToken middleware, verify req.user.id matches :userId OR req.user.role === 'admin' (403 if neither), extract query params (page=1, limit=20, status filter, startDate/endDate filters), query orders table with JOIN order_items: SELECT orders.*, COUNT(order_items.id) as itemCount FROM orders LEFT JOIN order_items ON orders.id = order_items.order_id WHERE orders.user_id = $1 [AND status = $2] [AND created_at BETWEEN $3 AND $4] GROUP BY orders.id ORDER BY created_at DESC LIMIT $5 OFFSET $6, count total matching orders for pagination, calculate summary stats (totalOrders, totalSpent SUM(total), averageOrder), return { success: true, orders: [{ id, date, total, status, itemCount, basketPhotoUrl }], pagination: { page, limit, total, totalPages }, summary: { totalOrders, totalSpent, averageOrder } }, cache responses for 1 minute, and log order history queries.
4. **Implement Order Details:** Create GET /api/orders/:orderId route handler with authenticateToken middleware, extract orderId from params, query SELECT orders.*, order_items.* FROM orders JOIN order_items ON orders.id = order_items.order_id WHERE orders.id = $1, return 404 if order not found, verify order.user_id matches req.user.id OR req.user.role === 'admin' (403 if neither - users can only see own orders), return { success: true, order: { id, userId, date, total, status, items: [{ id, productId, name, category, quantity, price, subtotal }], basketPhotoUrl, paymentMethod, paymentId, receiptUrl: '/receipts/' + orderId + '.pdf' (simulated), createdAt, updatedAt } } with full order details, cache individual order responses for 5 minutes, and log order detail access.

**Depends on:** Task 2.5 Output by Agent_Backend_Basket

### Task 2.8 – Implement user and admin management endpoints │ Agent_Backend_Orders

- **Objective:** Create admin-only endpoints for user management, order management, and analytics dashboard providing comprehensive administrative oversight with search, filtering, pagination, and aggregated statistics.
- **Output:** Admin route handlers (backend/src/routes/admin.js) with GET /api/admin/users (user list with stats), GET /api/admin/orders (all orders with filtering), GET /api/admin/analytics/dashboard (dashboard aggregations), GET /api/admin/products/stats (product analytics), all protected by admin authentication.
- **Guidance:** Depends on Task 2.2 Output by Agent_Backend_Core for requireAdmin middleware. All endpoints require authenticateToken + requireAdmin. Match frontend admin panel requirements.

1. **Implement User Management:** Create backend/src/routes/admin.js with GET /api/admin/users route handler with authenticateToken and requireAdmin middleware, extract query params (search, status filter, page, limit, sortBy, sortOrder), build query SELECT users.*, COUNT(DISTINCT orders.id) as totalOrders, COALESCE(SUM(orders.total), 0) as totalSpent FROM users LEFT JOIN orders ON users.id = orders.user_id WHERE [users.name ILIKE %$1% OR users.email ILIKE %$1%] [AND users.status = $2] GROUP BY users.id ORDER BY $3 $4 LIMIT $5 OFFSET $6 with dynamic WHERE and ORDER BY, count total users, calculate stats (totalUsers, activeUsers COUNT WHERE status='active', totalRevenue SUM(all orders)), return { success: true, users: [{ id, name, email, role, status, totalOrders, totalSpent, joinDate, lastLogin }], pagination, stats }, log admin user list access, and implement search across name and email fields.
2. **Implement Order Management:** Create GET /api/admin/orders route handler with admin auth, extract query params (search by orderId/customer name/email, status filter, date range, sortBy, sortOrder, page, limit), build complex query SELECT orders.*, users.name as userName, users.email as userEmail, COUNT(order_items.id) as itemCount FROM orders JOIN users ON orders.user_id = users.id LEFT JOIN order_items ON orders.id = order_items.order_id WHERE [orders.id ILIKE %$1% OR users.name ILIKE %$1% OR users.email ILIKE %$1%] [AND orders.status = $2] [AND orders.created_at BETWEEN $3 AND $4] GROUP BY orders.id, users.name, users.email ORDER BY $5 $6 LIMIT $7 OFFSET $8, count total matching orders, calculate aggregate stats (totalOrders, totalRevenue SUM(total), averageOrderValue), return { success: true, orders: [{ id, userId, userName, userEmail, date, total, status, itemCount, basketPhotoUrl }], pagination, stats }, and log admin order queries with filters applied.
3. **Implement Analytics Dashboard:** Create GET /api/admin/analytics/dashboard route handler with admin auth, extract query param (period: week/month/year, or custom startDate/endDate), calculate key metrics with aggregate queries: totalRevenue (SUM orders.total), totalOrders (COUNT orders), productsSold (SUM order_items.quantity), avgOrderValue (AVG orders.total), calculate change percentages vs previous period (revenueChange, ordersChange), generate time-series data for charts: revenueByDay array with SELECT DATE(created_at) as date, SUM(total) as revenue, COUNT(*) as orders FROM orders WHERE created_at >= $1 GROUP BY DATE(created_at) ORDER BY date, salesByCategory with SELECT products.category, SUM(order_items.quantity * order_items.price) as value FROM order_items JOIN products ON order_items.product_id = products.id GROUP BY category, calculate percentages for pie chart, generate recentActivity feed with SELECT orders.id, users.name, orders.created_at, orders.total FROM orders JOIN users ON orders.user_id = users.id ORDER BY orders.created_at DESC LIMIT 10, return { success: true, stats: { totalRevenue, totalOrders, productsSold, avgOrderValue, revenueChange, ordersChange }, charts: { revenueByDay, salesByCategory }, recentActivity }, cache dashboard data for 5 minutes, and log dashboard access.
4. **Implement Product Stats:** Create GET /api/admin/products/stats route handler with admin auth, query SELECT products.id, products.name, products.category, products.price, products.stock, COALESCE(SUM(order_items.quantity), 0) as sold, COALESCE(SUM(order_items.quantity * order_items.price), 0) as revenue FROM products LEFT JOIN order_items ON products.id = order_items.product_id GROUP BY products.id ORDER BY revenue DESC for product-level analytics, calculate metrics (units sold, revenue per product, stock turnover rate), return { success: true, products: [{ id, name, category, price, stock, sold, revenue, lastSold: <timestamp> }] }, identify low-stock products (stock < 20), identify best-sellers (sold > threshold), and log product stats queries.

**Depends on:** Task 2.2 Output by Agent_Backend_Core

---

## Phase 3: Flask Detection Service

### Task 3.1 – Set up Flask application structure and dependencies │ Agent_Detection

- **Objective:** Initialize the Flask application foundation for detection service with Python dependencies, CORS configuration for backend communication, logging integration from Task 1.6, and .env configuration loading for camera and detection parameters.
- **Output:** Flask app file (flask-detection/app.py) with Flask initialization, requirements.txt with all Python dependencies (Flask, opencv-python, ultralytics, requests, python-dotenv), CORS middleware, integrated Task 1.6 shared/logger.py, and .env loading.
- **Guidance:** Depends on Task 1.6 Output for shared/logger.py. Flask service runs independently from Node.js backend. Use CORS to allow backend API calls. All configuration loaded from .env for easy deployment changes.

- Initialize Flask app in flask-detection/app.py with Flask import (from flask import Flask, request, jsonify), create app instance (app = Flask(__name__)), load environment variables using python-dotenv (from dotenv import load_dotenv; load_dotenv()), and configure app settings (DEBUG mode from env, host='0.0.0.0' for network access, port from env or default 5000)
- Configure Flask routes and error handling: add CORS support using flask-cors (from flask_cors import CORS; CORS(app, origins=[os.getenv('BACKEND_API_URL')])) for backend communication, implement global error handler @app.errorhandler(Exception) logging errors and returning JSON { error: message }, add health check route @app.route('/health') returning { status: 'ok' } for monitoring, and ensure all responses use JSON format
- Integrate Python logging from Task 1.6 shared/logger.py: import sys and add parent directory to path (sys.path.append('../')) to access shared module, import logger (from shared.logger import logger), configure logger with LOG_FILE_PATH from .env, add request logging middleware using @app.before_request to log incoming requests (logger.info(f"{request.method} {request.path}")), and ensure all detection events use this logger
- Set up .env loading and configuration management: import os and dotenv, load .env file from flask-detection/.env, create config dictionary extracting CAMERA_INDEX (int), CONFIDENCE_THRESHOLD (float), DETECTION_INTERVAL (int), BACKEND_API_URL (string), YOLO_MODEL_PATH (string), LOG_FILE_PATH (string), validate all required env vars present (raise error if missing), and export config for use in other modules

**Depends on:** Task 1.6 Output

### Task 3.2 – Integrate YOLO11s model with Ultralytics │ Agent_Detection

- **Objective:** Integrate YOLO11s model using Ultralytics library with automatic model download, CPU/GPU device selection for Raspberry Pi compatibility, inference implementation, validation testing, and COCO class to product ID mapping creation for detection-to-product translation.
- **Output:** YOLO model module (flask-detection/models/yolo_detector.py) with model loading, inference function, COCO class mapping configuration file (flask-detection/config/coco_to_products.json), and validated detection on sample images.
- **Guidance:** Depends on Task 3.1 Output. Use Ultralytics YOLO library for YOLO11s support. Model weights auto-download on first run (fallback to manual download if network issues). COCO mapping queries backend product catalog for Apple → P001 mapping.

1. **Download YOLO Model:** Create flask-detection/models/yolo_detector.py importing Ultralytics (from ultralytics import YOLO), implement loadModel() function creating YOLO('yolo11s.pt') which auto-downloads weights to YOLO_MODEL_PATH on first run, add try-except for network failures with guidance: "Download yolo11s.pt manually from https://github.com/ultralytics/assets/releases and place in models/ directory", verify model file exists after load (os.path.exists(model_path)), log model loading success/failure, and return YOLO model instance for inference.
2. **Configure Model Loading:** Implement model initialization with device selection: detect available devices using torch.cuda.is_available(), prefer GPU if available for speed (device='cuda:0'), fall back to CPU for Raspberry Pi compatibility (device='cpu'), log selected device (logger.info(f"YOLO model loaded on {device}")), configure model inference parameters (conf=CONFIDENCE_THRESHOLD from .env, iou=0.45 for NMS), warm up model with dummy inference (model.predict(np.zeros((640,640,3))) to load weights into memory, and cache model instance to avoid reloading on every detection.
3. **Implement Inference Function:** Create runInference(frame) function accepting OpenCV image frame (numpy array), run YOLO inference with results = model.predict(frame, verbose=False), extract detections from results[0].boxes, parse each detection box: class_id (int), confidence (float 0-1), bounding_box (xyxy coordinates), filter detections by CONFIDENCE_THRESHOLD, return list of detections [{ 'class_id': 47, 'class_name': 'apple', 'confidence': 0.92, 'bbox': [x1,y1,x2,y2] }], log detection count per frame (logger.debug(f"Detected {len(detections)} objects")), and handle inference errors gracefully (return empty list, log error).
4. **Test Inference:** Create test script (flask-detection/tests/test_yolo.py) loading sample images (download COCO test images or use local photos), run inference on each image, verify detections returned with correct format, save annotated images with bounding boxes drawn using results[0].plot(), manually validate detection accuracy (are apples detected as class 47?), measure inference time (should be < 500ms for real-time), log test results with detection counts and timing, and document successful model validation.
5. **Create COCO Mapping:** Create flask-detection/config/coco_to_products.json storing mapping dictionary, query backend GET /api/products with search for COCO class names (class 47='apple' → search "apple" → productId 'P001'), manually map common COCO classes to ShopShadow products: { "47": { "coco_name": "apple", "product_id": "P001", "product_name": "Organic Apples", "price": 1.99 }, "46": { "coco_name": "banana", "product_id": "P002", "product_name": "Fresh Bananas", "price": 0.99 }, ... } for 10-15 detectable products, load mapping in yolo_detector.py (import json; mapping = json.load(open('config/coco_to_products.json'))), create getProductFromClass(class_id) function returning product details or None if unmapped, and document that unmapped classes are ignored (not sent to backend).

**Depends on:** Task 3.1 Output

### Task 3.3 – Implement USB camera capture system │ Agent_Detection

- **Objective:** Implement USB camera capture using OpenCV with configurable camera index, frame capture function, error handling for permission/device issues, camera testing/validation, and cleanup for graceful shutdown.
- **Output:** Camera module (flask-detection/camera/capture.py) with camera initialization, frame capture function, error handling with detailed logging, camera permissions guidance, and cleanup function.
- **Guidance:** Use OpenCV VideoCapture for cross-platform camera support. CAMERA_INDEX from .env (0 for MacBook built-in, 1+ for USB). Test frame capture works before proceeding. Handle common errors (permission denied, device not found).

1. **Initialize OpenCV VideoCapture:** Create flask-detection/camera/capture.py importing cv2 (import cv2), implement initCamera(camera_index) function creating VideoCapture(camera_index) from .env CAMERA_INDEX, set camera properties for optimal performance (cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640), cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480), cap.set(cv2.CAP_PROP_FPS, 30)), verify camera opened successfully with cap.isOpened(), log camera initialization (logger.info(f"Camera {camera_index} initialized")), return camera object for frame capture, and handle camera index errors (try different indexes if specified one fails).
2. **Implement Frame Capture:** Create captureFrame(camera) function calling ret, frame = camera.read(), check ret flag for successful capture (return None if False), validate frame is not empty (frame.shape has height/width > 0), convert color space if needed (OpenCV uses BGR, YOLO expects RGB: cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)), return numpy array frame ready for YOLO inference, log frame capture failures (logger.error("Failed to capture frame")), and implement retry logic (max 3 retries with 100ms delay) for transient capture failures.
3. **Test Camera Capture:** Create test_camera() function for validation: initialize camera with CAMERA_INDEX, capture test frame using captureFrame(), save test frame to file (cv2.imwrite('test_frame.jpg', frame)) for visual inspection, display frame properties (logger.info(f"Frame shape: {frame.shape}, dtype: {frame.dtype}")), verify frame can be processed by YOLO (run inference on test frame), release camera with cap.release(), and log test results confirming camera works correctly.
4. **Add Error Handling:** Implement comprehensive error handling in initCamera(): catch cv2.error for device not found (log: "Camera device {index} not found. Check CAMERA_INDEX in .env"), catch PermissionError for camera access denied (log: "Camera permission denied. On macOS: System Preferences → Security & Privacy → Camera → allow Terminal/IDE. On Linux: add user to video group"), add fallback camera detection (try indexes 0,1,2 if specified index fails, log available cameras), provide detailed troubleshooting guidance in logs for common camera issues, and implement graceful degradation (return None camera, don't crash app).
5. **Create Cleanup Function:** Implement releaseCamera(camera) function calling camera.release() to free camera resource, add cv2.destroyAllWindows() to close any OpenCV windows, log camera release (logger.info("Camera released")), register cleanup with atexit module for automatic cleanup on script exit (import atexit; atexit.register(releaseCamera, camera)), handle cleanup in signal handlers for SIGINT/SIGTERM (graceful shutdown), and ensure camera is released even if detection loop crashes.

**Depends on:** None (independent camera module)

### Task 3.4 – Create detection logic with confidence thresholding │ Agent_Detection

- **Objective:** Implement the complete detection pipeline processing camera frames through YOLO, filtering by confidence threshold, counting item quantities, routing high/low confidence to basket vs approval queue, mapping COCO classes to product IDs, formatting results as JSON payloads, and validating detection accuracy.
- **Output:** Detection logic module (flask-detection/detection/detector.py) with detection pipeline, confidence filtering, quantity counting, routing logic, product mapping integration, JSON formatting, and validated detection workflow.
- **Guidance:** Depends on Task 3.2 Output for YOLO model and COCO mapping. This is core detection logic combining camera frames → YOLO inference → confidence routing → product mapping. 70% threshold is critical business logic.

1. **Implement Detection Pipeline:** Create flask-detection/detection/detector.py with processFrame(frame, model, threshold) function: run YOLO inference using Task 3.2 runInference(frame), extract raw detections with class IDs and confidence scores, filter by threshold: high_conf = [d for d in detections if d['confidence'] >= threshold], low_conf = [d for d in detections if d['confidence'] < threshold], log detection counts (logger.info(f"Detected {len(high_conf)} high-conf, {len(low_conf)} low-conf items")), return tuple (high_confidence_detections, low_confidence_detections), and handle empty detection case (return ([], [])).
2. **Add Confidence Filtering:** Implement getConfidenceLevel(detection, threshold=0.7) function returning 'high' if detection.confidence >= threshold else 'low', create routeDetection(detection, threshold) function separating detections: if high confidence: prepare for basket API call, if low confidence: prepare for pending-items API call, validate threshold from CONFIDENCE_THRESHOLD env var (default 0.7 if not set), log routing decisions (logger.debug(f"Routing {detection['class_name']} (conf {detection['confidence']:.2f}) to {'basket' if high else 'pending'}")), and allow threshold override for testing (pass as parameter).
3. **Create Quantity Counting:** Implement countItems(detections) function grouping detections by class_id: from collections import Counter; class_counts = Counter([d['class_id'] for d in detections]), return dictionary { class_id: count } representing quantity of each detected item type, handle multiple instances of same class in single frame (e.g., 3 apples detected → { 47: 3 }), merge high and low confidence counts separately (high_counts, low_counts), log quantity counts (logger.info(f"Item quantities: {class_counts}")), and prepare quantity for backend payload.
4. **Implement Routing Logic:** Create routeDetections(detections, threshold, mapping) function: separate high/low confidence using confidence filtering, count items in each category using countItems(), for each unique class in high confidence: get product from COCO mapping (Task 3.2 getProductFromClass), prepare basket payload { productId, quantity: count, confidence: max(confidences for this class) }, for each unique class in low confidence: get product from mapping, prepare pending-items payload { productId, name, quantity: count, confidence }, filter out unmapped classes (classes not in COCO→product mapping), return (basket_payloads, pending_payloads) ready for backend API calls, and log routing summary.
5. **Map COCO to Products:** Integrate Task 3.2 COCO mapping: import getProductFromClass(class_id), for each detected class_id call mapping to get { product_id, product_name, price }, if class unmapped (returns None): log warning (logger.warn(f"COCO class {class_id} not mapped to product, ignoring")) and skip detection, if class mapped: include product metadata in payload (productId from mapping, name from mapping), validate product IDs match backend products table, and handle mapping errors gracefully (skip unmapped items, don't crash detection loop).
6. **Format JSON Payloads:** Create formatDetectionPayload(class_id, quantity, confidence, device_id, mapping) function: get product details from mapping, construct JSON matching backend API spec: { "productId": product['product_id'], "quantity": quantity, "confidence": confidence, "deviceId": device_id, "name": product['product_name'] } for pending items (backend needs name for display), validate all required fields present (productId, quantity, confidence, deviceId), serialize to JSON string for HTTP request, log payload (logger.debug(f"Formatted payload: {payload}")), and return formatted payload ready for requests.post().
7. **Test Detection Logic:** Create test script (flask-detection/tests/test_detection.py): load test image with multiple items (e.g., 3 apples, 2 bananas), run detection pipeline with processFrame(), verify detections separated by confidence (high_conf count, low_conf count), verify quantity counting works (apples=3, bananas=2), verify COCO mapping applied correctly (class 47 → P001 'Organic Apples'), verify JSON payloads formatted correctly (valid JSON, all fields present), test edge cases (no detections, all low confidence, unmapped classes), and document test results confirming detection logic works end-to-end.

**Depends on:** Task 3.2 Output

### Task 3.5 – Implement backend communication system │ Agent_Detection

- **Objective:** Create HTTP client for Flask to communicate with Node.js backend, implement device registration on startup to receive deviceId, send high-confidence detections to basket endpoint, send low-confidence detections to pending-items endpoint, handle network errors with retry logic, validate responses, and test backend integration.
- **Output:** Backend communication module (flask-detection/api/backend_client.py) with HTTP client, device registration, basket API calls, pending-items API calls, retry logic, response validation, and tested backend integration.
- **Guidance:** Depends on Tasks 2.5, 2.6, 3.4 Output. This is CRITICAL inter-service communication (identified as hardest challenge). Flask must register device on startup to get deviceId, then include deviceId in all detection payloads.

1. **Create HTTP Client:** Implement flask-detection/api/backend_client.py importing requests library, create BackendClient class with __init__(backend_url) accepting BACKEND_API_URL from .env, configure requests session with default headers { 'Content-Type': 'application/json' }, set connection timeout configuration (timeout=10 seconds for POST requests), add logging for all HTTP requests (logger.info(f"POST {endpoint} payload: {payload}")), handle connection errors with try-except, and create reusable _post(endpoint, payload) helper method.
2. **Implement Device Registration:** Add registerDevice() method in BackendClient: on Flask startup (before detection loop starts), POST to /api/devices/register endpoint (no payload needed), parse response { deviceId, code }, store deviceId in class instance (self.device_id = deviceId), log successful registration (logger.info(f"Registered device {deviceId} with code {code}")), handle registration failures with retry (max 3 attempts with exponential backoff 1s, 2s, 4s), raise exception if all retries fail (can't run detection without deviceId), and return deviceId for use in detection payloads.
3. **Implement Basket API Calls:** Add sendToBasket(product_id, quantity, confidence) method: construct payload { "productId": product_id, "quantity": quantity, "confidence": confidence, "deviceId": self.device_id } matching Task 2.5 API spec, POST to /api/basket/items endpoint, validate response status (200 or 201 success), parse response { success, basketItem }, log successful addition (logger.info(f"Added {quantity}x {product_id} to basket (conf {confidence:.2f})")), implement retry logic on network failures (requests.exceptions.ConnectionError, Timeout) with max 2 retries, log failures after retries exhausted (logger.error(f"Failed to add to basket after retries: {error}")), and return success boolean.
4. **Implement Pending-Items API Calls:** Add sendToPending(product_id, name, quantity, confidence) method: construct payload { "productId": product_id, "name": name, "quantity": quantity, "confidence": confidence, "deviceId": self.device_id } matching Task 2.6 API spec, POST to /api/basket/pending-items endpoint, validate response status (200/201), parse response { success, pendingItem }, log submission (logger.info(f"Sent {quantity}x {name} to pending approval (conf {confidence:.2f})")), implement error handling for 400 (device not connected - log and continue), retry on network failures (max 2 retries), and return success boolean.
5. **Add Comprehensive Error Handling:** Implement error handling for common network issues: requests.exceptions.ConnectionError (backend unreachable - log "Cannot reach backend at {url}, is it running?"), requests.exceptions.Timeout (backend slow - log "Backend request timed out after {timeout}s"), requests.exceptions.HTTPError (4xx/5xx responses - log status code and response body), validate backend is healthy on startup with GET /health endpoint, implement circuit breaker pattern (after 5 consecutive failures, pause API calls for 30s to avoid spamming logs), log all errors with detailed context (endpoint, payload, error message, stack trace), and continue detection loop even if backend calls fail (graceful degradation).
6. **Test Backend Communication:** Create test script (flask-detection/tests/test_backend.py): mock backend responses using requests-mock library, test device registration with mock POST /api/devices/register → { deviceId: 'test-123' }, verify deviceId stored correctly, test sendToBasket with mock successful response, verify payload format matches backend API spec exactly, test sendToPending with mock response, test retry logic by simulating ConnectionError then success on retry, test error handling for 400/500 responses, test circuit breaker after multiple failures, and document test results confirming backend communication works correctly.

**Depends on:** Tasks 2.5, 2.6, 3.4 Output

### Task 3.6 – Create detection loop and timing control │ Agent_Detection

- **Objective:** Implement the main detection loop orchestrating camera capture, YOLO inference, backend communication with 5-second intervals, startup validation of all components, graceful shutdown handling, and comprehensive logging of all detection events using Task 1.6 logger.
- **Output:** Main detection loop (flask-detection/main.py) with orchestration logic, timing control, startup checks, shutdown handlers, and complete logging integration.
- **Guidance:** Depends on Tasks 3.3, 3.4, 3.5 Output. This is the entry point bringing together camera → detection → backend communication. Loop runs every 5 seconds continuously. Must handle SIGINT (Ctrl+C) gracefully.

1. **Implement Main Loop:** Create flask-detection/main.py with main() function: import all modules (camera.capture, detection.detector, api.backend_client, models.yolo_detector, shared.logger), initialize components on startup (camera = initCamera(CAMERA_INDEX), model = loadModel(YOLO_MODEL_PATH), backend = BackendClient(BACKEND_API_URL), mapping = loadMapping('config/coco_to_products.json')), validate all components initialized (check camera not None, model loaded, backend healthy with /health check), register device with backend_client.registerDevice() to get deviceId, log startup success (logger.info("Detection service started successfully")), enter infinite loop with while True, and handle loop errors with try-except to prevent crashes.
2. **Add Detection Interval Control:** Inside main loop: capture frame using captureFrame(camera), skip iteration if frame is None (camera error), run detection pipeline processFrame(frame, model, CONFIDENCE_THRESHOLD), route detections using routeDetections(), send high-confidence to backend with backend_client.sendToBasket(), send low-confidence to backend with backend_client.sendToPending(), log detection results (items detected, items sent, failures), sleep for DETECTION_INTERVAL seconds using time.sleep(int(os.getenv('DETECTION_INTERVAL', 5))), and measure loop iteration time (should complete within interval, log warning if exceeds).
3. **Create Graceful Shutdown:** Import signal module (import signal, sys), implement signal handler def shutdown_handler(signum, frame): logger.info("Shutdown signal received, cleaning up..."), release camera using releaseCamera(camera), flush logger to write all buffered logs using logger.handlers[0].flush(), log final message (logger.info("Detection service stopped")), sys.exit(0), register shutdown handler for SIGINT and SIGTERM (signal.signal(signal.SIGINT, shutdown_handler), signal.signal(signal.SIGTERM, shutdown_handler)), and ensure cleanup happens even on exceptions (use try-finally block in main()).
4. **Implement Comprehensive Logging:** Import logger from Task 1.6 (from shared.logger import logger), log all detection events using Task 1.6 per-run log file: startup events (service started, camera initialized, model loaded, device registered), detection events per iteration (frame captured, detections found: { 'high_conf': count, 'low_conf': count, 'items': [product names] }), backend communication events (items sent to basket, items sent to pending, API call failures), errors with full context (camera failures, YOLO inference errors, network errors, unexpected exceptions), timing metrics (loop iteration time, inference time, API call time), and ensure all logs include timestamps, log levels, and metadata for debugging.

**Depends on:** Tasks 3.3, 3.4, 3.5 Output

---

## Phase 4: Frontend Enhancement & Integration

### Overview
Integrate the low-confidence approval workflow (NEW FEATURE from Phase 2) into the React frontend, replace mock data with real backend API integration, implement real-time basket polling synchronized with Flask detection service, and enhance admin dashboard with detection analytics.

**Agent:** Agent_Frontend
**Tasks:** 4.1, 4.2, 4.3, 4.4, 4.5, 4.6 (6 tasks)
**Dependencies:** Phase 2 (Backend API complete), Phase 3 (Flask Detection Service operational)

---

### Task 4.1 – Create Pending Items Approval Component │ Agent_Frontend

- **Objective:** Build a new React component PendingItemsCard to display low-confidence detections (<70%) awaiting user approval/decline with confidence scores, product details, and quantity adjustment controls using existing Radix UI and glassmorphic design patterns.
- **Output:** frontend/frontend/src/components/PendingItemsCard.tsx (150-200 lines) with TypeScript interfaces, approve/decline handlers, quantity stepper, confidence badges, loading states, and Framer Motion animations.
- **Guidance:** This is the UI for the NEW FEATURE. Match existing Dashboard glassmorphic aesthetic. Must handle async approve/decline actions with proper loading states.

1. **Create Component File and Interface:** Create frontend/frontend/src/components/PendingItemsCard.tsx with TypeScript interface PendingItem { id, product_id, name, quantity, confidence (0-1 scale), timestamp, device_id, status } and PendingItemsCardProps { items, onApprove: (itemId, quantity) => Promise<void>, onDecline: (itemId) => Promise<void>, isLoading? }, import motion/react, lucide-react icons, GlassCard, GlassButton, toast from sonner.
2. **Design Card Layout:** Use GlassCard wrapper with amber/yellow accent (indicates "needs attention"), header section with AlertCircle icon and "Items Awaiting Approval" title with count badge, conditional rendering for empty state (message: "All detections confirmed! No items need approval."), and list of pending items.
3. **Build Individual Pending Item Row:** For each item display card with product name (bold), confidence score badge with color coding (60-69% amber, 50-59% orange, <50% red), detected quantity (e.g., "Detected: 2 items"), relative timestamp ("2 minutes ago"), and confidence percentage badge (e.g., "65% confident").
4. **Implement Quantity Adjustment:** Add quantity stepper controls (minus/plus buttons), local state const [qty, setQty] = useState(item.quantity), min: 1, max: item.quantity * 2 (allow correction if detection undercounted), display current quantity in input field, use Radix UI Button or custom GlassButton.
5. **Create Action Buttons:** Two-button layout: "Approve" (primary, green accent) calls onApprove(item.id, qty), "Decline" (secondary, red accent) calls onDecline(item.id), show loading spinner during API call using isLoading prop, disable both buttons while loading, success toast messages ("Item approved and added to basket" or "Item declined"), use Framer Motion for button press animations.
6. **Add Visual Feedback:** Animate item entry with motion.div (slide-in from top), animate item exit when approved/declined (slide-out with fade), use AnimatePresence for smooth transitions, loading states disable buttons and show spinner icon, error handling displays error toast if API call fails and keeps item visible.
7. **Accessibility & Responsive Design:** ARIA labels on all interactive elements, keyboard navigation support (Tab, Enter, Escape), mobile-responsive stack buttons vertically on small screens, touch-friendly button sizes (min 44px height), screen reader announcements for approve/decline actions.
8. **Styling:** Match existing Dashboard glassmorphic aesthetic using Tailwind utility classes, amber/yellow header to differentiate from regular basket (blue/slate), confidence badge with gradient background, subtle box-shadow and backdrop-filter blur, hover states on action buttons.

**Depends on:** None (component only)

---

### Task 4.2 – Integrate Pending Items API into Dashboard │ Agent_Frontend

- **Objective:** Connect the PendingItemsCard component to backend API (GET /api/basket/:userId/pending-items, POST approve, POST decline), implement 5-second polling for real-time updates, handle approve/decline actions with proper state management, and synchronize with basket updates.
- **Output:** Updated frontend/frontend/src/components/Dashboard.tsx (add ~100 lines), API utility functions in frontend/frontend/src/utils/api.ts (create if not exists), working approve/decline flow with backend integration.
- **Guidance:** This integrates the NEW FEATURE with backend. Must handle authentication, polling, error states, and synchronize with basket state after approval.

1. **Create API Utility Functions:** Create frontend/frontend/src/utils/api.ts with const API_BASE = import.meta.env.VITE_API_URL || 'http://localhost:3001', authentication helper getAuthHeaders(token), implement fetchPendingItems(userId, token): Promise<PendingItem[]> calling GET /api/basket/:userId/pending-items, approvePendingItem(itemId, quantity, token): Promise<BasketResponse> calling POST /api/basket/pending-items/:itemId/approve with body { quantity }, declinePendingItem(itemId, token): Promise<void> calling POST /api/basket/pending-items/:itemId/decline, include error handling and type-safe responses.
2. **Update Dashboard Component State:** Import PendingItemsCard component, add state const [pendingItems, setPendingItems] = useState<PendingItem[]>([]), add state const [isLoadingPending, setIsLoadingPending] = useState(false), add state const [authToken, setAuthToken] = useState<string | null>(null) or use context, get userId from user context/props.
3. **Implement Pending Items Polling:** Create useEffect hook: if (!userId || !authToken) return; async fetchPending() { try { items = await fetchPendingItems(userId, authToken); setPendingItems(items); } catch (error) { console.error (no toast for polling errors to avoid spam); } }; fetchPending(); interval = setInterval(fetchPending, 5000); return clearInterval(interval);, match 5-second polling interval with basket polling from Phase 2 design.
4. **Implement Approve Handler:** Create handleApprovePending async (itemId, quantity) { setIsLoadingPending(true); try { updatedBasket = await approvePendingItem(itemId, quantity, authToken); setItems(updatedBasket.data.items); setPendingItems(prev => prev.filter(item => item.id !== itemId)); toast.success('Item approved and added to basket'); } catch (error) { toast.error('Failed to approve item. Please try again.'); } finally { setIsLoadingPending(false); } }, update basket total after approval.
5. **Implement Decline Handler:** Create handleDeclinePending async (itemId) { setIsLoadingPending(true); try { await declinePendingItem(itemId, authToken); setPendingItems(prev => prev.filter(item => item.id !== itemId)); toast.success('Item declined'); } catch (error) { toast.error('Failed to decline item. Please try again.'); } finally { setIsLoadingPending(false); } }.
6. **Add PendingItemsCard to Dashboard Layout:** Position PendingItemsCard ABOVE basket items in main content, conditional rendering: only show if pendingItems.length > 0, pass props: items={pendingItems}, onApprove={handleApprovePending}, onDecline={handleDeclinePending}, isLoading={isLoadingPending}, add visual separator between pending items and basket.
7. **Handle Authentication State:** For demo mode use mock token or skip auth, for production retrieve token from localStorage or context, handle 401 Unauthorized: clear token and redirect to login, handle 403 Forbidden: show error toast.
8. **Error Handling & Edge Cases:** Network errors show toast and retry on next poll, empty response sets pendingItems = [], item already approved/declined handle 400/404 gracefully, concurrent actions disable buttons during loading, stale data refresh both pending items and basket after action.
9. **Testing Scenarios:** Approve item with default quantity should appear in basket, approve item with adjusted quantity should reflect new quantity in basket, decline item should disappear from pending list, multiple pending items should be independently actionable, network failure should show error and allow retry.

**Depends on:** Task 4.1 Output

---

### Task 4.3 – Implement Real-Time Basket Polling │ Agent_Frontend

- **Objective:** Replace mock basket data in Dashboard with real backend API integration (GET /api/basket/:userId), implement 5-second polling for basket updates synchronized with Flask detection service, handle basket state management, and support real-time detection synchronization.
- **Output:** Updated frontend/frontend/src/components/Dashboard.tsx (replace mock data with API calls), basket API functions in frontend/frontend/src/utils/api.ts, real-time synchronization with Flask detection service.
- **Guidance:** This removes ALL mock data and creates the full detection → backend → frontend flow. Critical for end-to-end functionality.

1. **Create Basket API Functions:** Add to frontend/frontend/src/utils/api.ts: interface BasketItem { id, productId, name, price, category, imageUrl, quantity, confidence, subtotal, addedAt, deviceId }, interface BasketResponse { success, data: { items, total, itemCount } }, fetchBasket(userId, token): Promise<BasketResponse> calling GET /api/basket/:userId, removeBasketItem(itemId, token): Promise<void> calling DELETE /api/basket/items/:itemId, include error handling.
2. **Remove Mock Data from Dashboard:** Delete mock items array const mockItems: BasketItem[] = [...], change initial state: const [items, setItems] = useState<BasketItem[]>([]), add loading state: const [isLoadingBasket, setIsLoadingBasket] = useState(true).
3. **Implement Basket Polling:** Create useEffect for basket polling: if (!userId || !authToken) return; async fetchBasketData() { try { basketResponse = await fetchBasket(userId, authToken); setItems(basketResponse.data.items); setIsLoadingBasket(false); } catch (error) { console.error; if (isLoadingBasket) toast.error('Failed to load basket'); } }; fetchBasketData(); interval = setInterval(fetchBasketData, 5000); return clearInterval(interval);, polling interval matches Flask detection interval (5 seconds).
4. **Update Remove Item Handler:** Modify handleRemoveItem to call backend API: async (id) { try { await removeBasketItem(id, authToken); setItems(items.filter(item => item.id !== id)); toast.success('Item removed from basket'); } catch (error) { toast.error('Failed to remove item. Please try again.'); } }, keep TODO comment about security concern (manual deletion in production).
5. **Update Total Calculation:** Use backend-provided total instead of calculating client-side: const [basketTotal, setBasketTotal] = useState(0); const [itemCount, setItemCount] = useState(0); update in fetchBasketData: setBasketTotal(basketResponse.data.total); setItemCount(basketResponse.data.itemCount);, fallback calculate client-side if backend doesn't provide.
6. **Add Loading States:** Show skeleton UI while isLoadingBasket === true using Radix UI Skeleton component or custom loading state, skeleton for basket items: {isLoadingBasket ? <div className="space-y-3">{[1,2,3].map(i => <div key={i} className="h-20 bg-slate-200/50 animate-pulse rounded-lg" />)}</div> : actual basket items}.
7. **Handle Empty Basket State:** Keep existing EmptyState component, show when items.length === 0 && !isLoadingBasket, message: "Your basket is empty. Start shopping or connect a device to begin!".
8. **Synchronization Logic:** Ensure basket updates immediately after pending item approval (Task 4.2), Flask detection service adds item, manual item removal, no duplicate polling requests (cancel previous request if new one starts using AbortController or debounce), handle race conditions.
9. **Connection Status Integration:** Update isConnected state based on device pairing status, fetch device status from backend: GET /api/devices/:userId/status, show "Disconnected" if no active device, disable checkout if not connected.
10. **Error Handling:** 401 Unauthorized redirect to login, 403 Forbidden show permission error, 404 Not Found empty basket, 500 Server Error show error toast and retry on next poll, network offline show offline indicator.
11. **Performance Optimization:** Memoize basket items with useMemo, debounce rapid state updates, use React.memo for BasketItem components to prevent unnecessary re-renders, cancel fetch requests on component unmount.

**Depends on:** Phase 2 backend basket endpoints, Phase 3 Flask detection service

---

### Task 4.4 – Device Connection Integration │ Agent_Frontend

- **Objective:** Connect the ConnectionPage component to backend device pairing API (POST /api/devices/connect), implement 4-digit code entry and validation, display connection status in Dashboard using real device status polling, and handle device disconnection scenarios.
- **Output:** Updated frontend/frontend/src/components/ConnectionPage.tsx (integrate with backend API), updated frontend/frontend/src/components/ConnectionStatus.tsx (show real device status), device API functions in frontend/frontend/src/utils/api.ts.
- **Guidance:** This enables users to pair their mobile app with the detection device (Raspberry Pi or MacBook camera running Flask service).

1. **Create Device API Functions:** Add to frontend/frontend/src/utils/api.ts: interface Device { id, code, userId, status: 'active' | 'inactive' | 'pending', lastHeartbeat, createdAt }, connectDevice(code, token): Promise<Device> calling POST /api/devices/connect with body { code }, getDeviceStatus(userId, token): Promise<Device | null> calling GET /api/devices/:userId/status, disconnectDevice(deviceId, token): Promise<void> calling POST /api/devices/:deviceId/disconnect, include error handling.
2. **Update ConnectionPage Component:** Remove mock connection logic, add state: const [code, setCode] = useState('') (4 digits), const [isConnecting, setIsConnecting] = useState(false), const [error, setError] = useState<string | null>(null), use Radix UI InputOTP component for code entry (already imported).
3. **Implement 4-Digit Code Entry:** Use InputOTP component with 4 slots: <InputOTP maxLength={4} value={code} onChange={(value) => setCode(value)} pattern="^[0-9]*$"><InputOTPGroup><InputOTPSlot index={0-3} /></InputOTPGroup></InputOTP>, auto-submit when 4 digits entered, numeric keyboard on mobile.
4. **Implement Connection Handler:** Create handleConnect async () { if (code.length !== 4) { setError('Please enter a 4-digit code'); return; } setIsConnecting(true); setError(null); try { device = await connectDevice(code, authToken); toast.success(`Device connected! ID: ${device.id}`); onConnect(device); } catch (error) { setError(error.message || 'Invalid code. Please try again.'); setCode(''); toast.error('Connection failed'); } finally { setIsConnecting(false); } }.
5. **Add Code Display for Demo:** For demo mode display available device code from backend, fetch from GET /api/devices/available (returns list of pending devices), show hint: "Demo code: 1234" (if demo device exists).
6. **Update ConnectionStatus Component:** Modify to show real device status, fetch device status on mount and poll every 10 seconds, display states: "Connected" (green dot) device active with heartbeat <60s ago, "Disconnected" (red dot) no device or heartbeat >60s ago, "Pending" (yellow dot) device paired but no heartbeat yet, add click handler to show device details (ID, last heartbeat).
7. **Implement Device Status Polling in Dashboard:** Add useEffect in Dashboard for device status: if (!userId || !authToken) return; async checkDeviceStatus() { device = await getDeviceStatus(userId, authToken); setConnectedDevice(device); setIsConnected(device?.status === 'active'); }; checkDeviceStatus(); interval = setInterval(checkDeviceStatus, 10000); return clearInterval(interval);.
8. **Handle Disconnection:** Add "Disconnect Device" option in Dashboard settings/menu, confirm dialog before disconnecting using Radix UI AlertDialog: <AlertDialog><AlertDialogTrigger>Disconnect Device</AlertDialogTrigger><AlertDialogContent><AlertDialogTitle>Disconnect Device?</AlertDialogTitle><AlertDialogDescription>Your basket items will be saved, but new detections will stop.</AlertDialogDescription><AlertDialogAction onClick={handleDisconnect}>Disconnect</AlertDialogAction><AlertDialogCancel>Cancel</AlertDialogCancel></AlertDialogContent></AlertDialog>, clear device state after disconnection.
9. **Error States:** Invalid code (not found) show "Invalid code. Please check and try again.", code already in use show "This device is already connected to another user.", network error show "Connection failed. Please check your internet.", device inactive show reconnect option.
10. **UX Enhancements:** Animate code entry with Framer Motion, shake animation on error, success animation on connection, visual feedback during connection attempt, skip connection page if already connected (check on mount).

**Depends on:** Phase 2 device pairing endpoints

---

### Task 4.5 – Admin Detection Analytics Dashboard │ Agent_Frontend

- **Objective:** Enhance the admin dashboard with detection analytics including high/low confidence detection breakdown, device activity monitoring, pending items queue overview across all users, and real-time detection stats with charts and visualizations.
- **Output:** Updated frontend/frontend/src/components/admin/AdminOverview.tsx (add detection analytics section), new component frontend/frontend/src/components/admin/DetectionAnalytics.tsx (optional, or inline), admin API functions for detection stats.
- **Guidance:** Provides admin visibility into detection system performance, pending approvals across all users, and device health monitoring. Use recharts for visualizations.

1. **Create Admin Detection Stats API:** Add to backend (if not exists): GET /api/admin/detection-stats (requires admin auth) returning DetectionStats { totalDetections, highConfidence, lowConfidence, pendingApprovals, approvalRate (percentage), avgConfidence, detectionsToday, detectionsByHour: [{hour, count}], deviceActivity: [{deviceId, lastHeartbeat, detectionCount, status}] }, or use existing analytics endpoint from Phase 2 Task 2.8.
2. **Fetch Detection Stats:** Add to frontend/frontend/src/utils/api.ts: getDetectionStats(token): Promise<DetectionStats> calling GET /api/admin/detection-stats, include error handling.
3. **Update AdminOverview Component:** Import Chart components from recharts (already in package.json), add state: const [detectionStats, setDetectionStats] = useState<DetectionStats | null>(null), fetch stats on mount and poll every 15 seconds.
4. **Create Detection Overview Cards:** Add 4 stat cards in grid layout: "Total Detections Today" (large number with trend indicator), "High Confidence" (count and percentage with green accent), "Low Confidence" (count and percentage with amber accent), "Pending Approvals" (count with link to pending items queue), use GlassCard for each stat, add icon for each metric (CheckCircle, AlertCircle, Clock, TrendingUp).
5. **Build Confidence Distribution Chart:** Use recharts BarChart or PieChart, show split between high confidence (≥70%) and low confidence (<70%), color coding: Green for high and Amber for low, display percentages on chart.
6. **Create Detections Timeline Chart:** Use recharts LineChart or AreaChart, X-axis: Hours (last 24 hours), Y-axis: Detection count, show peak detection times.
7. **Add Device Activity Monitor:** Table showing all registered devices: Device ID (truncated with tooltip for full ID), Last Heartbeat (relative time: "2 minutes ago"), Detection Count (today), Status indicator (green dot = active, red dot = inactive), sort by last heartbeat (most recent first), highlight inactive devices (heartbeat >5 minutes ago).
8. **Create Pending Approvals Queue:** Table of all pending items across all users: User email, Product name, Confidence score, Time pending, Quick view button (modal with item details), filter by confidence range, sort by time pending (oldest first).
9. **Add Real-Time Updates:** Implement polling (15-second interval), auto-refresh charts and stats, visual indicator when data updates (subtle flash or badge).
10. **Performance Metrics:** Add "Approval Rate" metric: (approved / (approved + declined)) * 100, add "Avg Confidence" metric: Average of all detections, show improvement trends (comparison to yesterday).
11. **Export Functionality (Optional Enhancement):** "Export Report" button, download CSV with detection stats, date range selector.

**Depends on:** Phase 2 admin endpoints, Phase 3 Flask detection service

---

### Task 4.6 – End-to-End Integration Testing & Polish │ Agent_Frontend

- **Objective:** Test the complete user flow from device connection → detection → pending approval → basket → checkout, fix any integration bugs, improve error handling, add loading states, polish UX, and document test results comprehensively.
- **Output:** Integration test documentation in frontend/frontend/src/INTEGRATION_TEST_RESULTS.md, bug fixes and UX improvements across all Phase 4 components, updated error handling and loading states, final QA checklist.
- **Guidance:** Comprehensive testing task to ensure all pieces work together. Focus on edge cases, error scenarios, and user experience polish.

1. **Create Test Plan Document:** Create frontend/frontend/src/INTEGRATION_TEST_RESULTS.md, document test scenarios: Happy path (full flow works), Error scenarios (network failures, auth errors), Edge cases (empty states, concurrent actions), Performance (polling performance, memory leaks), Cross-browser compatibility.
2. **Test Complete User Flow (Happy Path):** Step 1: User logs in (demo@email.com / 1234), Step 2: Navigate to ConnectionPage, Step 3: Enter 4-digit device code, Step 4: Connect successfully → Dashboard loads, Step 5: Flask detection service detects item (run python flask-detection/main.py), Step 6: High confidence item (≥70%) appears in basket automatically, Step 7: Low confidence item (<70%) appears in PendingItemsCard, Step 8: User approves pending item with quantity adjustment, Step 9: Approved item moves to basket, Step 10: User declines another pending item, Step 11: Declined item disappears, Step 12: User removes item from basket, Step 13: User proceeds to checkout, Step 14: Order created successfully. Expected: All steps complete without errors.
3. **Test Error Scenarios:** Network Failure (disconnect internet during basket polling, expected: show offline indicator and retry on reconnect), Invalid Auth Token (manually clear localStorage token, expected: redirect to login with error message), Device Disconnection (stop Flask service, expected: ConnectionStatus shows red and user can reconnect), Duplicate Approval (approve item then try again for race condition, expected: handle 404 gracefully with error toast), Concurrent Actions (approve multiple pending items rapidly, expected: queue actions and prevent duplicate requests).
4. **Test Edge Cases:** Empty States (empty basket shows EmptyState, no pending items hides PendingItemsCard or shows empty message, no products shows EmptyState in ProductCatalog), Maximum Quantities (approve pending item with max quantity 2x detected, expected: basket reflects correct quantity), Rapid Polling (check Network tab for duplicate requests, expected: no duplicates within polling interval), Stale Data (approve item and check if basket updates immediately not wait for next poll, expected: optimistic update or immediate refresh).
5. **Performance Testing:** Memory Leaks (run app for 5 minutes with polling active, check Chrome DevTools Memory tab, expected: no memory growth over time), Polling Performance (open Network tab and observe polling requests, expected: requests complete <500ms with no errors), Component Re-renders (use React DevTools Profiler, expected: minimal unnecessary re-renders).
6. **Cross-Browser Testing:** Test on Chrome, Safari, Firefox, test on mobile (iOS Safari, Chrome Android), verify glassmorphic styling works (backdrop-filter support), test touch interactions on mobile.
7. **Fix Identified Bugs:** Document each bug in test results document, create GitHub issues or fix immediately, prioritize critical bugs (breaks user flow) vs. minor bugs (cosmetic).
8. **UX Polish Improvements:** Loading States (add skeleton loaders for initial basket load, spinner during pending item actions, disabled state on buttons during API calls), Error Messages (user-friendly messages avoiding technical jargon, actionable errors with "Retry" button), Animations (smooth transitions between states, Framer Motion animations for item entry/exit, loading spinner animations), Empty States (helpful messages with next actions, icons to make empty states visually appealing).
9. **Accessibility Audit:** Run Lighthouse accessibility audit, check keyboard navigation (Tab through all interactive elements), test screen reader (VoiceOver on Mac, NVDA on Windows), verify ARIA labels on all custom components, color contrast check (WCAG AA compliance).
10. **Create Final QA Checklist:** Document all tested scenarios, list known issues (if any remain), recommendation: "Ready for production" or "Needs fixes", include screenshots of key flows.
11. **Documentation Updates:** Update 01-user-flows-and-states.md with pending items flow, update 03-api-endpoints-and-data.md if API changes made, add screenshots to README (optional).

**Depends on:** Tasks 4.1, 4.2, 4.3, 4.4, 4.5 Output

